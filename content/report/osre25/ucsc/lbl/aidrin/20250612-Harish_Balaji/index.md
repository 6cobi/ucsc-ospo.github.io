---
title: "Improving AI Data Pipelines in AIDRIN: A Privacy-Centric and Multimodal Expansion"
summary: Enhancing AIDRIN with privacy metrics and multimodal support under mentorship from LBNL researchers as part of GSoC 2025.
authors: 
- harishbalaji
- jeanlucabez
- surenbyna
tags: [
  "AIDRIN",
  "AI readiness",
  "data quality",
  "dataset privacy",
  "GSoC2025",
  "HPC",
  "LBNL",
  "Lawrence Berkeley Lab",
  "lbl",
  "open source",
  "osre25",
  "UCB",
  "UC",
  "University of California Berkeley"
]

categories: ["Google Summer of Code", "GSoC 2025", "Open Source", "AI Readiness"]

date: 2025-06-12
lastmod: 2025-06-12
featured: true
draft: false
user_groups:
- 2025 Contributors

# Featured image
image:
  caption: "AIDRIN - inspecting dataset readiness for AI pipelines"
  focal_point: Top
  preview_only: false
---

Hi, Iâ€™m **Harish Balaji** ðŸ‘‹

Iâ€™m a Masterâ€™s student at NYU, focusing on Artificial Intelligence, Machine Learning, and Cybersecurity. I am particularly interested in how scalable systems and responsible AI practices can work together, especially in ensuring that data quality directly supports reliable model performance.

This summer, I am contributing to **AIDRIN** (AI Data Readiness Inspector) through **Google Summer of Code 2025**, under the mentorship of **Dr. Jean Luca Bez** and **Prof. Suren Byna** from the [Scientific Data Management Group](https://crd.lbl.gov/divisions/scidata/sdm/) at **Lawrence Berkeley National Laboratory (LBNL)**.

---

### Why Data Readiness Matters

In machine learning, one principle always applies:  
> *"Garbage in, garbage out."*

Even the most advanced models can fail if the data used for training is biased, incomplete, or poorly structured. **AIDRIN** tackles this problem by offering tools to assess dataset quality across key dimensions such as:

- **Privacy preservation**
- **Fairness and class balance**
- **Interpretability**
- **Multimodal compatibility** (including structured data, images, text, and audio)

By making these checks measurable and actionable, AIDRIN helps researchers and engineers make better-informed decisions before deploying models.

---

### What This Project Is About

Throughout GSoC 2025, I will be working to extend AIDRINâ€™s evaluation capabilities. This includes strengthening its privacy assessment tools and expanding support for datasets beyond traditional structured formats.

Details of specific metrics, technical design choices, and implementation results will follow in future blog posts.

---

### Looking Ahead

As the AI community shifts toward more responsible and data-centric development practices, I believe tools like AIDRIN will play a critical role in shaping how we evaluate and prepare datasets. This project gives me the opportunity to contribute to that vision by helping build infrastructure that encourages transparency, reproducibility, and trust in machine learning workflows.

In the coming weeks, Iâ€™ll be diving deeper into design, development, and integration efforts. Iâ€™m looking forward to sharing technical progress and insights in future posts as the project evolves.

If you're working on similar problems, exploring dataset quality, or just curious about building better AI from the ground up, Iâ€™d love to connect and exchange ideas.

You can also check out my GSoC 2025 proposal for a deeper overview of the project goals.

ðŸ‘‰ [Read my GSoC 2025 proposal here](https://drive.google.com/file/d/1RUyU2fHkc8GZ9vTj5SUr6jj84ZaRUvNt/view)

---


