---
title: "Improving AI Data Pipelines in AIDRIN: A Privacy-Centric and Multimodal Expansion"
summary: Enhancing AIDRIN with privacy metrics and multimodal support under mentorship from LBNL researchers as part of GSoC 2025.
authors: 
- harishbalaji
- jeanlucabez
- surenbyna
tags: [
  "AIDRIN",
  "AI readiness",
  "data quality",
  "dataset privacy",
  "GSoC2025",
  "HPC",
  "LBNL",
  "Lawrence Berkeley Lab",
  "lbl",
  "open source",
  "osre25",
  "UCB",
  "UC",
  "University of California Berkeley"
]

categories: ["Google Summer of Code", "GSoC 2025", "Open Source", "AI Readiness"]

date: 2025-06-12
lastmod: 2025-06-12
featured: true
draft: false
user_groups:
- 2025 Contributors

# Featured image
image:
  caption: "AIDRIN - inspecting dataset readiness for AI pipelines"
  focal_point: Top
  preview_only: false
---

Hi ðŸ‘‹

Iâ€™m **Harish Balaji**, a Masterâ€™s student at NYU with a focus on Artificial Intelligence, Machine Learning, and Cybersecurity. Iâ€™m especially interested in building scalable systems that align with responsible AI principles. For me, data quality isnâ€™t just a technical detail â€” itâ€™s central to building models that are reliable, fair, and reproducible.

This summer, Iâ€™m contributing to **AIDRIN** (AI Data Readiness Inspector) through **Google Summer of Code 2025**, under the mentorship of **Dr. Jean Luca Bez** and **Prof. Suren Byna** from the [Scientific Data Management Group](https://crd.lbl.gov/divisions/scidata/sdm/) at **Lawrence Berkeley National Laboratory (LBNL)**.

AIDRIN is an open-source framework that helps researchers and practitioners assess whether a dataset is truly ready to be used in real-world AI workflows.

## Why this work matters

In machine learning, one principle always holds true:  
> **"Garbage in, garbage out."**

Even the most advanced models can fail if trained on incomplete, biased, or unstructured data. Thatâ€™s where AIDRIN comes in, offering practical tools to evaluate datasets across dimensions such as privacy, fairness, balance, interpretability, and support for multiple modalities.

By making these qualities measurable, AIDRIN helps ensure that datasets are not just large or complex, but also trustworthy and well-prepared for use in AI systems.

## My focus this summer

This summer, Iâ€™ll be focusing on extending AIDRINâ€™s evaluation capabilities. My work will include improving support for privacy metrics and enabling readiness assessments for non-tabular datasets. More technical details will follow in upcoming posts as the project develops.

## What comes next

As the AI community moves toward more data-centric practices, I believe frameworks like AIDRIN are essential. They help shift the conversation from "Does the model work?" to "Was the data ready in the first place?"

In the coming weeks, Iâ€™ll be diving deeper into development, testing, and evaluation. Iâ€™m excited to contribute to a tool that emphasizes transparency and reproducibility in the AI lifecycle â€” and to share what I learn along the way.

If youâ€™re working on similar challenges or care about improving data quality for AI, Iâ€™d love to connect. You can also explore my GSoC 2025 proposal below for a broader overview of the project goals:

ðŸ‘‰ [Read my GSoC 2025 proposal here](https://drive.google.com/file/d/1RUyU2fHkc8GZ9vTj5SUr6jj84ZaRUvNt/view)

*This is the first in a 3-part blog series documenting my GSoC journey with AIDRIN. Stay tuned for technical updates and behind-the-scenes insights as the summer unfolds!*
